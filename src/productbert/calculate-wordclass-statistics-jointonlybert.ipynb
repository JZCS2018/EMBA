{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from pdb import set_trace\n",
    "\n",
    "from pathlib import Path\n",
    "Path('../../data/processed/explain_labeling/pictures/jointbert/onlybert/').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand_left</th>\n",
       "      <th>brand_left_wordclasses</th>\n",
       "      <th>title_left</th>\n",
       "      <th>title_left_wordclasses</th>\n",
       "      <th>brand_right</th>\n",
       "      <th>brand_right_wordclasses</th>\n",
       "      <th>title_right</th>\n",
       "      <th>title_right_wordclasses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>1</td>\n",
       "      <td>[logitech]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[logitech, 920-004536, mk270, wireless, combo,...</td>\n",
       "      <td>[brand name, model number, model name, char. a...</td>\n",
       "      <td>[logitech]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[logitech, mk270, wireless, keyboard, and, mou...</td>\n",
       "      <td>[brand name, model name, product type, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16723236#1379306</th>\n",
       "      <td>16723236#1379306</td>\n",
       "      <td>1</td>\n",
       "      <td>[hp, enterprise]</td>\n",
       "      <td>[brand name, brand name]</td>\n",
       "      <td>[300682-b21, hp, 4gb, (2x2gb), 266mhz, sdram, ...</td>\n",
       "      <td>[model number, brand name, char. attr., char. ...</td>\n",
       "      <td>[netcna]</td>\n",
       "      <td>[stopword]</td>\n",
       "      <td>[300682-b21, 4gb, (2x2gb), compaq, proliant, b...</td>\n",
       "      <td>[model number, char. attr., char. attr., model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900676#8501437</th>\n",
       "      <td>2900676#8501437</td>\n",
       "      <td>0</td>\n",
       "      <td>[hp]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[hp, chromebook, 14, g4, -, 14, celeron, n2840...</td>\n",
       "      <td>[brand name, model name, model name, model nam...</td>\n",
       "      <td>[hp]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[hp, chromebook, 14, g4, -, 14, celeron, n2940...</td>\n",
       "      <td>[brand name, model name, model name, model nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613113#14761048</th>\n",
       "      <td>1613113#14761048</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seagate, guardian, barracuda, st4000lm024, -,...</td>\n",
       "      <td>[brand name, model name, model name, model num...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seagate, guardian, barracuda, st2000lm015, -,...</td>\n",
       "      <td>[brand name, model name, model name, model num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050100#5511322</th>\n",
       "      <td>11050100#5511322</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[liebert, psi-xr, ps2200rt3]</td>\n",
       "      <td>[brand name, model name, model number]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[liebert, psi, xr, 1920va, 1920w, 120v, line-i...</td>\n",
       "      <td>[brand name, model name, model name, model nam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pair_id  label        brand_left  \\\n",
       "pair_id                                                       \n",
       "3483338#13088419  3483338#13088419      1        [logitech]   \n",
       "16723236#1379306  16723236#1379306      1  [hp, enterprise]   \n",
       "2900676#8501437    2900676#8501437      0              [hp]   \n",
       "1613113#14761048  1613113#14761048      0                []   \n",
       "11050100#5511322  11050100#5511322      1                []   \n",
       "\n",
       "                    brand_left_wordclasses  \\\n",
       "pair_id                                      \n",
       "3483338#13088419              [brand name]   \n",
       "16723236#1379306  [brand name, brand name]   \n",
       "2900676#8501437               [brand name]   \n",
       "1613113#14761048                        []   \n",
       "11050100#5511322                        []   \n",
       "\n",
       "                                                         title_left  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [logitech, 920-004536, mk270, wireless, combo,...   \n",
       "16723236#1379306  [300682-b21, hp, 4gb, (2x2gb), 266mhz, sdram, ...   \n",
       "2900676#8501437   [hp, chromebook, 14, g4, -, 14, celeron, n2840...   \n",
       "1613113#14761048  [seagate, guardian, barracuda, st4000lm024, -,...   \n",
       "11050100#5511322                       [liebert, psi-xr, ps2200rt3]   \n",
       "\n",
       "                                             title_left_wordclasses  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [brand name, model number, model name, char. a...   \n",
       "16723236#1379306  [model number, brand name, char. attr., char. ...   \n",
       "2900676#8501437   [brand name, model name, model name, model nam...   \n",
       "1613113#14761048  [brand name, model name, model name, model num...   \n",
       "11050100#5511322             [brand name, model name, model number]   \n",
       "\n",
       "                 brand_right brand_right_wordclasses  \\\n",
       "pair_id                                                \n",
       "3483338#13088419  [logitech]            [brand name]   \n",
       "16723236#1379306    [netcna]              [stopword]   \n",
       "2900676#8501437         [hp]            [brand name]   \n",
       "1613113#14761048          []                      []   \n",
       "11050100#5511322          []                      []   \n",
       "\n",
       "                                                        title_right  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [logitech, mk270, wireless, keyboard, and, mou...   \n",
       "16723236#1379306  [300682-b21, 4gb, (2x2gb), compaq, proliant, b...   \n",
       "2900676#8501437   [hp, chromebook, 14, g4, -, 14, celeron, n2940...   \n",
       "1613113#14761048  [seagate, guardian, barracuda, st2000lm015, -,...   \n",
       "11050100#5511322  [liebert, psi, xr, 1920va, 1920w, 120v, line-i...   \n",
       "\n",
       "                                            title_right_wordclasses  \n",
       "pair_id                                                              \n",
       "3483338#13088419  [brand name, model name, product type, product...  \n",
       "16723236#1379306  [model number, char. attr., char. attr., model...  \n",
       "2900676#8501437   [brand name, model name, model name, model nam...  \n",
       "1613113#14761048  [brand name, model name, model name, model num...  \n",
       "11050100#5511322  [brand name, model name, model name, model nam...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordclass_dict = {'1':'model number',\n",
    "                 '2':'brand name',\n",
    "                 '3':'model name',\n",
    "                 '4':'char. attr.',\n",
    "                 '5':'stopword',\n",
    "                 '6':'product type',\n",
    "                 '7':'descr. word',\n",
    "                 '8':'non-english word',\n",
    "                 '9':'noisy model number',\n",
    "                 '10':'noise from other product'}\n",
    "\n",
    "wordclass_labels = pd.read_csv('../../data/processed/explain_labeling/wordclass_labeling_labeled.csv')\n",
    "wordclass_labels = wordclass_labels.set_index('pair_id', drop=False)\n",
    "wordclass_labels = wordclass_labels.fillna('')\n",
    "wordclass_labels[['brand_left', 'title_left', 'brand_right', 'title_right']] = wordclass_labels[['brand_left', 'title_left', 'brand_right', 'title_right']].applymap(lambda x: x.lower().split())\n",
    "wordclass_labels[['brand_left_wordclasses', 'title_left_wordclasses', 'brand_right_wordclasses', 'title_right_wordclasses']] = wordclass_labels[['brand_left_wordclasses', 'title_left_wordclasses', 'brand_right_wordclasses', 'title_right_wordclasses']].applymap(lambda x: literal_eval(x))\n",
    "wordclass_labels[['brand_left_wordclasses', 'title_left_wordclasses', 'brand_right_wordclasses', 'title_right_wordclasses']] = wordclass_labels[['brand_left_wordclasses', 'title_left_wordclasses', 'brand_right_wordclasses', 'title_right_wordclasses']].applymap(lambda x: [wordclass_dict[x] for x in x])\n",
    "wordclass_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same word got different classes: wireless in 3483338#13088419\n",
      "same word got different classes: network in 3012473#-8080417\n",
      "same word got different classes: controller in 10236395#-10099949\n",
      "same word got different classes: 14 in 8501437#2195482\n",
      "same word got different classes: gaming in 4997700#17067318\n",
      "same word got different classes: 14 in 8501437#26606\n",
      "same word got different classes: x99 in 8163032#15301739\n",
      "same word got different classes: 14 in 2900676#8501437\n",
      "same word got different classes: drive in 124883#-10596400\n",
      "same word got different classes: 14 in 8501437#2195482\n",
      "same word got different classes: 14 in 8501437#26606\n",
      "same word got different classes: 3d in 2273550#2649714\n",
      "same word got different classes: 3 in 6346941#11774848\n",
      "same word got different classes: usb in 2807522#15298918\n",
      "same word got different classes: processor in 14334319#1812858\n"
     ]
    }
   ],
   "source": [
    "def build_dict_left(row):\n",
    "    wordclass_dict_left = dict()\n",
    "    \n",
    "    for i, word in enumerate(row['brand_left']):\n",
    "        if word not in wordclass_dict_left.keys():\n",
    "                wordclass_dict_left[word] = row['brand_left_wordclasses'][i]\n",
    "        else:\n",
    "            if wordclass_dict_left[word] != row['brand_left_wordclasses'][i]:\n",
    "                print(f'same word got different classes: {word} in {row[\"pair_id\"]}')\n",
    "                \n",
    "    for i, word in enumerate(row['title_left']):\n",
    "        if word not in wordclass_dict_left.keys():\n",
    "            try:\n",
    "                wordclass_dict_left[word] = row['title_left_wordclasses'][i]\n",
    "            except IndexError:\n",
    "                print(row['pair_id'])\n",
    "        else:\n",
    "            if wordclass_dict_left[word] != row['title_left_wordclasses'][i]:\n",
    "                print(f'same word got different classes: {word} in {row[\"pair_id\"]}')\n",
    "                \n",
    "    return wordclass_dict_left\n",
    "\n",
    "def build_dict_right(row):\n",
    "    wordclass_dict_right = dict()\n",
    "                \n",
    "    for i, word in enumerate(row['brand_right']):\n",
    "        if word not in wordclass_dict_right.keys():\n",
    "            wordclass_dict_right[word] = row['brand_right_wordclasses'][i]\n",
    "        else:\n",
    "            if wordclass_dict_right[word] != row['brand_right_wordclasses'][i]:\n",
    "                print(f'same word got different classes: {word} in {row[\"pair_id\"]}')\n",
    "                \n",
    "    for i, word in enumerate(row['title_right']):\n",
    "        if word not in wordclass_dict_right.keys():\n",
    "            wordclass_dict_right[word] = row['title_right_wordclasses'][i]\n",
    "        else:\n",
    "            if wordclass_dict_right[word] != row['title_right_wordclasses'][i]:\n",
    "                print(f'same word got different classes: {word} in {row[\"pair_id\"]}')\n",
    "                \n",
    "    return wordclass_dict_right\n",
    "\n",
    "\n",
    "wordclass_labels['labeldict_left'] = wordclass_labels.apply(build_dict_left, axis=1)\n",
    "wordclass_labels['labeldict_right'] = wordclass_labels.apply(build_dict_right, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>label</th>\n",
       "      <th>brand_left</th>\n",
       "      <th>brand_left_wordclasses</th>\n",
       "      <th>title_left</th>\n",
       "      <th>title_left_wordclasses</th>\n",
       "      <th>brand_right</th>\n",
       "      <th>brand_right_wordclasses</th>\n",
       "      <th>title_right</th>\n",
       "      <th>title_right_wordclasses</th>\n",
       "      <th>labeldict_left</th>\n",
       "      <th>labeldict_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>1</td>\n",
       "      <td>[logitech]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[logitech, 920-004536, mk270, wireless, combo,...</td>\n",
       "      <td>[brand name, model number, model name, char. a...</td>\n",
       "      <td>[logitech]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[logitech, mk270, wireless, keyboard, and, mou...</td>\n",
       "      <td>[brand name, model name, product type, product...</td>\n",
       "      <td>{'logitech': 'brand name', '920-004536': 'mode...</td>\n",
       "      <td>{'logitech': 'brand name', 'mk270': 'model nam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16723236#1379306</th>\n",
       "      <td>16723236#1379306</td>\n",
       "      <td>1</td>\n",
       "      <td>[hp, enterprise]</td>\n",
       "      <td>[brand name, brand name]</td>\n",
       "      <td>[300682-b21, hp, 4gb, (2x2gb), 266mhz, sdram, ...</td>\n",
       "      <td>[model number, brand name, char. attr., char. ...</td>\n",
       "      <td>[netcna]</td>\n",
       "      <td>[stopword]</td>\n",
       "      <td>[300682-b21, 4gb, (2x2gb), compaq, proliant, b...</td>\n",
       "      <td>[model number, char. attr., char. attr., model...</td>\n",
       "      <td>{'hp': 'brand name', 'enterprise': 'brand name...</td>\n",
       "      <td>{'netcna': 'stopword', '300682-b21': 'model nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900676#8501437</th>\n",
       "      <td>2900676#8501437</td>\n",
       "      <td>0</td>\n",
       "      <td>[hp]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[hp, chromebook, 14, g4, -, 14, celeron, n2840...</td>\n",
       "      <td>[brand name, model name, model name, model nam...</td>\n",
       "      <td>[hp]</td>\n",
       "      <td>[brand name]</td>\n",
       "      <td>[hp, chromebook, 14, g4, -, 14, celeron, n2940...</td>\n",
       "      <td>[brand name, model name, model name, model nam...</td>\n",
       "      <td>{'hp': 'brand name', 'chromebook': 'model name...</td>\n",
       "      <td>{'hp': 'brand name', 'chromebook': 'model name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613113#14761048</th>\n",
       "      <td>1613113#14761048</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seagate, guardian, barracuda, st4000lm024, -,...</td>\n",
       "      <td>[brand name, model name, model name, model num...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[seagate, guardian, barracuda, st2000lm015, -,...</td>\n",
       "      <td>[brand name, model name, model name, model num...</td>\n",
       "      <td>{'seagate': 'brand name', 'guardian': 'model n...</td>\n",
       "      <td>{'seagate': 'brand name', 'guardian': 'model n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050100#5511322</th>\n",
       "      <td>11050100#5511322</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[liebert, psi-xr, ps2200rt3]</td>\n",
       "      <td>[brand name, model name, model number]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[liebert, psi, xr, 1920va, 1920w, 120v, line-i...</td>\n",
       "      <td>[brand name, model name, model name, model nam...</td>\n",
       "      <td>{'liebert': 'brand name', 'psi-xr': 'model nam...</td>\n",
       "      <td>{'liebert': 'brand name', 'psi': 'model name',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pair_id  label        brand_left  \\\n",
       "pair_id                                                       \n",
       "3483338#13088419  3483338#13088419      1        [logitech]   \n",
       "16723236#1379306  16723236#1379306      1  [hp, enterprise]   \n",
       "2900676#8501437    2900676#8501437      0              [hp]   \n",
       "1613113#14761048  1613113#14761048      0                []   \n",
       "11050100#5511322  11050100#5511322      1                []   \n",
       "\n",
       "                    brand_left_wordclasses  \\\n",
       "pair_id                                      \n",
       "3483338#13088419              [brand name]   \n",
       "16723236#1379306  [brand name, brand name]   \n",
       "2900676#8501437               [brand name]   \n",
       "1613113#14761048                        []   \n",
       "11050100#5511322                        []   \n",
       "\n",
       "                                                         title_left  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [logitech, 920-004536, mk270, wireless, combo,...   \n",
       "16723236#1379306  [300682-b21, hp, 4gb, (2x2gb), 266mhz, sdram, ...   \n",
       "2900676#8501437   [hp, chromebook, 14, g4, -, 14, celeron, n2840...   \n",
       "1613113#14761048  [seagate, guardian, barracuda, st4000lm024, -,...   \n",
       "11050100#5511322                       [liebert, psi-xr, ps2200rt3]   \n",
       "\n",
       "                                             title_left_wordclasses  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [brand name, model number, model name, char. a...   \n",
       "16723236#1379306  [model number, brand name, char. attr., char. ...   \n",
       "2900676#8501437   [brand name, model name, model name, model nam...   \n",
       "1613113#14761048  [brand name, model name, model name, model num...   \n",
       "11050100#5511322             [brand name, model name, model number]   \n",
       "\n",
       "                 brand_right brand_right_wordclasses  \\\n",
       "pair_id                                                \n",
       "3483338#13088419  [logitech]            [brand name]   \n",
       "16723236#1379306    [netcna]              [stopword]   \n",
       "2900676#8501437         [hp]            [brand name]   \n",
       "1613113#14761048          []                      []   \n",
       "11050100#5511322          []                      []   \n",
       "\n",
       "                                                        title_right  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [logitech, mk270, wireless, keyboard, and, mou...   \n",
       "16723236#1379306  [300682-b21, 4gb, (2x2gb), compaq, proliant, b...   \n",
       "2900676#8501437   [hp, chromebook, 14, g4, -, 14, celeron, n2940...   \n",
       "1613113#14761048  [seagate, guardian, barracuda, st2000lm015, -,...   \n",
       "11050100#5511322  [liebert, psi, xr, 1920va, 1920w, 120v, line-i...   \n",
       "\n",
       "                                            title_right_wordclasses  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  [brand name, model name, product type, product...   \n",
       "16723236#1379306  [model number, char. attr., char. attr., model...   \n",
       "2900676#8501437   [brand name, model name, model name, model nam...   \n",
       "1613113#14761048  [brand name, model name, model name, model num...   \n",
       "11050100#5511322  [brand name, model name, model name, model nam...   \n",
       "\n",
       "                                                     labeldict_left  \\\n",
       "pair_id                                                               \n",
       "3483338#13088419  {'logitech': 'brand name', '920-004536': 'mode...   \n",
       "16723236#1379306  {'hp': 'brand name', 'enterprise': 'brand name...   \n",
       "2900676#8501437   {'hp': 'brand name', 'chromebook': 'model name...   \n",
       "1613113#14761048  {'seagate': 'brand name', 'guardian': 'model n...   \n",
       "11050100#5511322  {'liebert': 'brand name', 'psi-xr': 'model nam...   \n",
       "\n",
       "                                                    labeldict_right  \n",
       "pair_id                                                              \n",
       "3483338#13088419  {'logitech': 'brand name', 'mk270': 'model nam...  \n",
       "16723236#1379306  {'netcna': 'stopword', '300682-b21': 'model nu...  \n",
       "2900676#8501437   {'hp': 'brand name', 'chromebook': 'model name...  \n",
       "1613113#14761048  {'seagate': 'brand name', 'guardian': 'model n...  \n",
       "11050100#5511322  {'liebert': 'brand name', 'psi': 'model name',...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordclass_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exp</th>\n",
       "      <th>token</th>\n",
       "      <th>attribute</th>\n",
       "      <th>tuple</th>\n",
       "      <th>weight</th>\n",
       "      <th>data_inx</th>\n",
       "      <th>explanation_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_inx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>0</td>\n",
       "      <td>920-004536</td>\n",
       "      <td>title</td>\n",
       "      <td>L</td>\n",
       "      <td>-0.495467</td>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>&lt;lime.explanation.Explanation object at 0x7fc5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>0</td>\n",
       "      <td>mk270</td>\n",
       "      <td>title</td>\n",
       "      <td>R</td>\n",
       "      <td>0.076100</td>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>&lt;lime.explanation.Explanation object at 0x7fc5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>0</td>\n",
       "      <td>mk270</td>\n",
       "      <td>title</td>\n",
       "      <td>L</td>\n",
       "      <td>0.067290</td>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>&lt;lime.explanation.Explanation object at 0x7fc5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>0</td>\n",
       "      <td>logitech</td>\n",
       "      <td>title</td>\n",
       "      <td>R</td>\n",
       "      <td>0.052160</td>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>&lt;lime.explanation.Explanation object at 0x7fc5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>0</td>\n",
       "      <td>logitech</td>\n",
       "      <td>title</td>\n",
       "      <td>L</td>\n",
       "      <td>0.027271</td>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>&lt;lime.explanation.Explanation object at 0x7fc5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 exp       token attribute tuple    weight          data_inx  \\\n",
       "data_inx                                                                       \n",
       "3483338#13088419   0  920-004536     title     L -0.495467  3483338#13088419   \n",
       "3483338#13088419   0       mk270     title     R  0.076100  3483338#13088419   \n",
       "3483338#13088419   0       mk270     title     L  0.067290  3483338#13088419   \n",
       "3483338#13088419   0    logitech     title     R  0.052160  3483338#13088419   \n",
       "3483338#13088419   0    logitech     title     L  0.027271  3483338#13088419   \n",
       "\n",
       "                                                    explanation_obj  \n",
       "data_inx                                                             \n",
       "3483338#13088419  <lime.explanation.Explanation object at 0x7fc5...  \n",
       "3483338#13088419  <lime.explanation.Explanation object at 0x7fc5...  \n",
       "3483338#13088419  <lime.explanation.Explanation object at 0x7fc5...  \n",
       "3483338#13088419  <lime.explanation.Explanation object at 0x7fc5...  \n",
       "3483338#13088419  <lime.explanation.Explanation object at 0x7fc5...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations_distilbert = pd.read_pickle('../../data/processed/explain_labeling/explained/distilbert.pkl.gz')\n",
    "explanations_deepmatcher = pd.read_pickle('../../data/processed/explain_labeling/explained/deepmatcher.pkl.gz')\n",
    "explanations_bert = pd.read_pickle('../../data/processed/explain_labeling/explained/bert.pkl.gz')\n",
    "explanations_jointbert = pd.read_pickle('../../data/processed/explain_labeling/explained/jointbert.pkl.gz')\n",
    "explanations_distilbert = explanations_distilbert.set_index('data_inx', drop=False)\n",
    "explanations_deepmatcher = explanations_deepmatcher.set_index('data_inx', drop=False)\n",
    "explanations_bert = explanations_bert.set_index('data_inx', drop=False)\n",
    "explanations_jointbert = explanations_jointbert.set_index('data_inx', drop=False)\n",
    "explanations_deepmatcher.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>challenge_1</th>\n",
       "      <th>challenge_2</th>\n",
       "      <th>challenge_3</th>\n",
       "      <th>challenge_4</th>\n",
       "      <th>challenge_5</th>\n",
       "      <th>challenge_6</th>\n",
       "      <th>challenge_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3483338#13088419</th>\n",
       "      <td>3483338#13088419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16723236#1379306</th>\n",
       "      <td>16723236#1379306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900676#8501437</th>\n",
       "      <td>2900676#8501437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613113#14761048</th>\n",
       "      <td>1613113#14761048</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050100#5511322</th>\n",
       "      <td>11050100#5511322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pair_id  challenge_1  challenge_2  challenge_3  \\\n",
       "pair_id                                                                     \n",
       "3483338#13088419  3483338#13088419            0            1            0   \n",
       "16723236#1379306  16723236#1379306            1            0            0   \n",
       "2900676#8501437    2900676#8501437            0            1            0   \n",
       "1613113#14761048  1613113#14761048            1            0            0   \n",
       "11050100#5511322  11050100#5511322            0            0            0   \n",
       "\n",
       "                  challenge_4  challenge_5  challenge_6  challenge_7  \n",
       "pair_id                                                               \n",
       "3483338#13088419            0            0            0            1  \n",
       "16723236#1379306            0            0            0            0  \n",
       "2900676#8501437             0            0            0            1  \n",
       "1613113#14761048            0            0            0            0  \n",
       "11050100#5511322            0            0            0            1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenges_df = pd.read_csv('../../data/processed/explain_labeling/challenge_lookup.csv')\n",
    "challenges_df = challenges_df.set_index('pair_id', drop=False)\n",
    "\n",
    "challenges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilbert_results = pd.read_pickle('../../src/productbert/saved/models/BT-DistilBERT-FT-computers-xlarge-swctest/0921_172448/predictions.pkl.gz')\n",
    "# distilbert_results['label_distilbert'] = distilbert_results['predictions'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "# distilbert_results = distilbert_results.set_index('pair_id', drop=False)\n",
    "# distilbert_results = distilbert_results[['pair_id', 'label_distilbert']]\n",
    "\n",
    "# deepmatcher_results = pd.read_csv('../../data/processed/inspection/wdc-lspc/deepmatcher/rnn_abs-diff_standard_epochs50_ratio6_batch16_lr0.001_lrdecay0.8_fasttext.en.bin_brand-title_preprocessed_computers_trainonly_xlarge_magellan_pairs_run1_preprocessed_computers_new_testset_1500_magellan_pairs.csv.gz')\n",
    "# deepmatcher_results['label_deepmatcher'] = deepmatcher_results['match_score'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "# deepmatcher_results = deepmatcher_results.set_index('pair_id', drop=False)\n",
    "# deepmatcher_results = deepmatcher_results[['pair_id', 'label_deepmatcher']]\n",
    "\n",
    "jointbert_results = pd.read_pickle('../../src/productbert/saved/test/models/JointBERT-FT-shoes-small-test/0927_194115/predictions.pkl.gz')\n",
    "jointbert_results['label_jointbert'] = jointbert_results['predictions'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "jointbert_results = jointbert_results.set_index('pair_id', drop=False)\n",
    "jointbert_results = jointbert_results[['pair_id', 'label_jointbert']]\n",
    "\n",
    "# bert_results = pd.read_pickle('../../src/productbert/saved/models/BT-BERT-FT-computers-xlarge-swctest/1024_164723/predictions.pkl.gz')\n",
    "# bert_results['label_bert'] = bert_results['predictions'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "# bert_results = bert_results.set_index('pair_id', drop=False)\n",
    "# bert_results = bert_results[['pair_id', 'label_bert']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instances_distilbert = explanations_distilbert['data_inx'].unique().tolist()\n",
    "# instances_deepmatcher = explanations_deepmatcher['data_inx'].unique().tolist()\n",
    "# instances_bert = explanations_bert['data_inx'].unique().tolist()\n",
    "instances_jointbert = explanations_jointbert['data_inx'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'3483338#13088419'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '3483338#13088419'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fb9b3722b1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# explanations_distilbert['label_deepmatcher'] = explanations_distilbert.apply(lambda x: deepmatcher_results.loc[x.name]['label_deepmatcher'], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# explanations_distilbert['label_bert'] = explanations_distilbert.apply(lambda x: bert_results.loc[x.name]['label_bert'], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexplanations_distilbert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_jointbert'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanations_distilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjointbert_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_jointbert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mexplanations_distilbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanations_distilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data_inx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'pair_id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6876\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6877\u001b[0m         )\n\u001b[0;32m-> 6878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6880\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 result = libreduction.compute_reduction(\n\u001b[0m\u001b[1;32m    296\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 )\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.compute_reduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-fb9b3722b1f5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# explanations_distilbert['label_deepmatcher'] = explanations_distilbert.apply(lambda x: deepmatcher_results.loc[x.name]['label_deepmatcher'], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# explanations_distilbert['label_bert'] = explanations_distilbert.apply(lambda x: bert_results.loc[x.name]['label_bert'], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexplanations_distilbert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_jointbert'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanations_distilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjointbert_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_jointbert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mexplanations_distilbert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanations_distilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'data_inx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'pair_id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3535\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3536\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3537\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/jointbert/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '3483338#13088419'"
     ]
    }
   ],
   "source": [
    "# explanations_distilbert['wordclass'] = explanations_distilbert.apply(lambda x: wordclass_labels.loc[x.name]['labeldict_left'][x['token']] if x['tuple'] == 'L' else wordclass_labels.loc[x.name]['labeldict_right'][x['token']], axis=1)\n",
    "# explanations_distilbert['label'] = explanations_distilbert.apply(lambda x: wordclass_labels.loc[x.name]['label'], axis=1)\n",
    "# explanations_distilbert['label_distilbert'] = explanations_distilbert.apply(lambda x: distilbert_results.loc[x.name]['label_distilbert'], axis=1)\n",
    "# explanations_distilbert['label_jointdistilbert'] = explanations_distilbert.apply(lambda x: jointdistilbert_results.loc[x.name]['label_jointdistilbert'], axis=1)\n",
    "# explanations_distilbert['label_deepmatcher'] = explanations_distilbert.apply(lambda x: deepmatcher_results.loc[x.name]['label_deepmatcher'], axis=1)\n",
    "# explanations_distilbert['label_bert'] = explanations_distilbert.apply(lambda x: bert_results.loc[x.name]['label_bert'], axis=1)\n",
    "explanations_distilbert['label_jointbert'] = explanations_distilbert.apply(lambda x: jointbert_results.loc[x.name]['label_jointbert'], axis=1)\n",
    "\n",
    "explanations_distilbert = explanations_distilbert.rename(columns={'data_inx':'pair_id'})\n",
    "\n",
    "# explanations_deepmatcher['wordclass'] = explanations_deepmatcher.apply(lambda x: wordclass_labels.loc[x.name]['labeldict_left'][x['token']] if x['tuple'] == 'L' else wordclass_labels.loc[x.name]['labeldict_right'][x['token']], axis=1)\n",
    "# explanations_deepmatcher['label'] = explanations_deepmatcher.apply(lambda x: wordclass_labels.loc[x.name]['label'], axis=1)\n",
    "# explanations_deepmatcher['label_distilbert'] = explanations_deepmatcher.apply(lambda x: distilbert_results.loc[x.name]['label_distilbert'], axis=1)\n",
    "# explanations_deepmatcher['label_jointdistilbert'] = explanations_deepmatcher.apply(lambda x: jointdistilbert_results.loc[x.name]['label_jointdistilbert'], axis=1)\n",
    "# explanations_deepmatcher['label_deepmatcher'] = explanations_deepmatcher.apply(lambda x: deepmatcher_results.loc[x.name]['label_deepmatcher'], axis=1)\n",
    "# explanations_deepmatcher['label_bert'] = explanations_deepmatcher.apply(lambda x: bert_results.loc[x.name]['label_bert'], axis=1)\n",
    "explanations_deepmatcher['label_jointbert'] = explanations_deepmatcher.apply(lambda x: jointbert_results.loc[x.name]['label_jointbert'], axis=1)\n",
    "\n",
    "explanations_deepmatcher = explanations_deepmatcher.rename(columns={'data_inx':'pair_id'})\n",
    "\n",
    "# explanations_bert['wordclass'] = explanations_bert.apply(lambda x: wordclass_labels.loc[x.name]['labeldict_left'][x['token']] if x['tuple'] == 'L' else wordclass_labels.loc[x.name]['labeldict_right'][x['token']], axis=1)\n",
    "# explanations_bert['label'] = explanations_bert.apply(lambda x: wordclass_labels.loc[x.name]['label'], axis=1)\n",
    "# explanations_bert['label_distilbert'] = explanations_bert.apply(lambda x: distilbert_results.loc[x.name]['label_distilbert'], axis=1)\n",
    "# explanations_bert['label_jointdistilbert'] = explanations_bert.apply(lambda x: jointdistilbert_results.loc[x.name]['label_jointdistilbert'], axis=1)\n",
    "# explanations_bert['label_deepmatcher'] = explanations_bert.apply(lambda x: deepmatcher_results.loc[x.name]['label_deepmatcher'], axis=1)\n",
    "# explanations_bert['label_bert'] = explanations_bert.apply(lambda x: bert_results.loc[x.name]['label_bert'], axis=1)\n",
    "explanations_bert['label_jointbert'] = explanations_bert.apply(lambda x: jointbert_results.loc[x.name]['label_jointbert'], axis=1)\n",
    "\n",
    "explanations_bert = explanations_bert.rename(columns={'data_inx':'pair_id'})\n",
    "\n",
    "# explanations_jointbert['wordclass'] = explanations_jointbert.apply(lambda x: wordclass_labels.loc[x.name]['labeldict_left'][x['token']] if x['tuple'] == 'L' else wordclass_labels.loc[x.name]['labeldict_right'][x['token']], axis=1)\n",
    "# explanations_jointbert['label'] = explanations_jointbert.apply(lambda x: wordclass_labels.loc[x.name]['label'], axis=1)\n",
    "# explanations_jointbert['label_distilbert'] = explanations_jointbert.apply(lambda x: distilbert_results.loc[x.name]['label_distilbert'], axis=1)\n",
    "# explanations_jointbert['label_jointdistilbert'] = explanations_jointbert.apply(lambda x: jointdistilbert_results.loc[x.name]['label_jointdistilbert'], axis=1)\n",
    "# explanations_jointbert['label_deepmatcher'] = explanations_jointbert.apply(lambda x: deepmatcher_results.loc[x.name]['label_deepmatcher'], axis=1)\n",
    "# explanations_jointbert['label_bert'] = explanations_jointbert.apply(lambda x: bert_results.loc[x.name]['label_bert'], axis=1)\n",
    "explanations_jointbert['label_jointbert'] = explanations_jointbert.apply(lambda x: jointbert_results.loc[x.name]['label_jointbert'], axis=1)\n",
    "\n",
    "explanations_jointbert = explanations_jointbert.rename(columns={'data_inx':'pair_id'})\n",
    "\n",
    "explanations_deepmatcher.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2.0)\n",
    "\n",
    "def plot_explanations(explanations, filename = 'default'):\n",
    "    median_width = 0.2\n",
    "\n",
    "    g = sns.FacetGrid(explanations, col=\"label\", sharex=True, sharey=True, height=8.27, aspect=11.7/8.27, ylim=(-0.4, 0.4))\n",
    "    g.map_dataframe(sns.stripplot, x='wordclass', y='weight', hue='model', palette='tab10', dodge=True, order=['model number', 'brand name', 'model name', 'char. attr.', 'stopword', 'product type', 'descr. word'], hue_order=['BERT','JointBERT', 'Deepmatcher'], zorder=1)\n",
    "    g.set_axis_labels(None, \"weight\")\n",
    "    g.add_legend()\n",
    "    \n",
    "    median_values_bert = {}\n",
    "    median_values_jointbert = {}\n",
    "    median_values_deepmatcher = {}\n",
    "    \n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        \n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "\n",
    "        for tick, text in zip(ax.get_xticks(), ax.get_xticklabels()):\n",
    "            sample_name = text.get_text()  # \"X\" or \"Y\"\n",
    "            \n",
    "            median_val_bert = explanations[(explanations['wordclass']==sample_name) & (explanations['label']==i) & (explanations['model']=='BERT')].weight.median()\n",
    "            median_val_jointbert = explanations[(explanations['wordclass']==sample_name) & (explanations['label']==i) & (explanations['model']=='JointBERT')].weight.median()\n",
    "            median_val_deepmatcher = explanations[(explanations['wordclass']==sample_name) & (explanations['label']==i) & (explanations['model']=='Deepmatcher')].weight.median()\n",
    "            \n",
    "            if sample_name in median_values_bert.keys():\n",
    "                median_values_bert[sample_name].append(median_val_bert)\n",
    "                median_values_jointbert[sample_name].append(median_val_jointbert)\n",
    "                median_values_deepmatcher[sample_name].append(median_val_deepmatcher)\n",
    "            else:\n",
    "                median_values_bert[sample_name] = [median_val_bert]\n",
    "                median_values_jointbert[sample_name] = [median_val_jointbert]\n",
    "                median_values_deepmatcher[sample_name] = [median_val_deepmatcher]\n",
    "            \n",
    "            \n",
    "            # plot horizontal lines across the column, centered on the tick\n",
    "            ax.plot([tick-2*median_width, tick-1.0*median_width], [median_val_bert, median_val_bert],\n",
    "                   'k', lw=4, zorder=2)\n",
    "            ax.plot([tick-0.5*median_width, tick+0.5*median_width], [median_val_jointbert, median_val_jointbert],\n",
    "                   'k', lw=4, zorder=2)\n",
    "            ax.plot([tick+1.0*median_width, tick+2*median_width], [median_val_deepmatcher, median_val_deepmatcher],\n",
    "                   'k', lw=4, zorder=2)\n",
    "\n",
    "        if 'label' in median_values_bert.keys():\n",
    "                median_values_bert['label'].append(i)\n",
    "                median_values_jointbert['label'].append(i)\n",
    "                median_values_deepmatcher['label'].append(i)\n",
    "        else:\n",
    "            median_values_bert['label'] = [i]\n",
    "            median_values_jointbert['label'] = [i]\n",
    "            median_values_deepmatcher['label'] = [i]\n",
    "        \n",
    "        bert_df = explanations[(explanations['label']==i) & (explanations['model']=='BERT')]\n",
    "        jointbert_df = explanations[(explanations['label']==i) & (explanations['model']=='JointBERT')]\n",
    "        deepmatcher_df = explanations[(explanations['label']==i) & (explanations['model']=='Deepmatcher')]\n",
    "        \n",
    "        count_bert_correct = len(bert_df[bert_df['label'] == bert_df['label_bert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_bert_wrong = len(bert_df[bert_df['label'] != bert_df['label_bert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_bert_all = count_bert_correct + count_bert_wrong\n",
    "\n",
    "        count_jointbert_correct = len(jointbert_df[jointbert_df['label'] == jointbert_df['label_jointbert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_jointbert_wrong = len(jointbert_df[jointbert_df['label'] != jointbert_df['label_jointbert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_jointbert_all = count_jointbert_correct + count_jointbert_wrong\n",
    "        \n",
    "        count_deepmatcher_correct = len(deepmatcher_df[deepmatcher_df['label'] == deepmatcher_df['label_deepmatcher']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_deepmatcher_wrong = len(deepmatcher_df[deepmatcher_df['label'] != deepmatcher_df['label_deepmatcher']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_deepmatcher_all = count_deepmatcher_correct + count_deepmatcher_wrong\n",
    "        \n",
    "        print(f'Label: {i}: BERT correct: {count_bert_correct}/{count_bert_all}')\n",
    "        print(f'Label: {i}: JointBERT correct: {count_jointbert_correct}/{count_jointbert_all}')\n",
    "        print(f'Label: {i}: Deepmatcher correct: {count_deepmatcher_correct}/{count_deepmatcher_all}')\n",
    "    \n",
    "    median_bert_df = pd.DataFrame.from_dict(median_values_bert)\n",
    "    median_bert_df['model'] = 'BERT'\n",
    "    median_jointbert_df = pd.DataFrame.from_dict(median_values_jointbert)\n",
    "    median_jointbert_df['model'] = 'JointBERT'\n",
    "    median_deepmatcher_df = pd.DataFrame.from_dict(median_values_deepmatcher)\n",
    "    median_deepmatcher_df['model'] = 'Deepmatcher'\n",
    "    \n",
    "    median_to_file = median_bert_df.append(median_jointbert_df)\n",
    "    median_to_file = median_to_file.append(median_deepmatcher_df)\n",
    "    \n",
    "    #median_to_file.to_csv(f'../../data/processed/explain_labeling/pictures/MEDIAN_{filename}.csv', index=False, float_format=\"%.4f\")\n",
    "    \n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    #g.fig.suptitle(f'Combined Classifications\\nChallenge: {name}')\n",
    "    plt.savefig(f'../../data/processed/explain_labeling/pictures/jointbert/onlybert/MEDIAN_{filename}.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_explanations_avg(explanations, filename = 'default'):\n",
    "    median_width = 0.2\n",
    "\n",
    "    g = sns.FacetGrid(explanations, col=\"label\", sharex=True, sharey=True, height=8.27, aspect=11.7/8.27, ylim=(-0.4, 0.4))\n",
    "    g.map_dataframe(sns.stripplot, x='wordclass', y='weight', hue='model', palette='tab10', dodge=True, order=['model number', 'brand name', 'model name', 'char. attr.', 'stopword', 'product type', 'descr. word'], hue_order=['BERT','JointBERT', 'Deepmatcher'], zorder=1)\n",
    "    g.set_axis_labels(\"wordclass\", \"weight\")\n",
    "    g.add_legend()\n",
    "    \n",
    "    median_values_bert = {}\n",
    "    median_values_jointbert = {}\n",
    "    median_values_deepmatcher = {}\n",
    "    \n",
    "    for i, ax in enumerate(g.axes.flat):\n",
    "        \n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "\n",
    "        for tick, text in zip(ax.get_xticks(), ax.get_xticklabels()):\n",
    "            sample_name = text.get_text()  # \"X\" or \"Y\"\n",
    "            \n",
    "            median_val_bert = explanations[(explanations['wordclass']==sample_name) & (explanations['label']==i) & (explanations['model']=='BERT')].weight.mean()\n",
    "            median_val_jointbert = explanations[(explanations['wordclass']==sample_name) & (explanations['label']==i) & (explanations['model']=='JointBERT')].weight.mean()\n",
    "            median_val_deepmatcher = explanations[(explanations['wordclass']==sample_name) & (explanations['label']==i) & (explanations['model']=='Deepmatcher')].weight.mean()\n",
    "            \n",
    "            if sample_name in median_values_bert.keys():\n",
    "                median_values_bert[sample_name].append(median_val_bert)\n",
    "                median_values_jointbert[sample_name].append(median_val_jointbert)\n",
    "                median_values_deepmatcher[sample_name].append(median_val_deepmatcher)\n",
    "            else:\n",
    "                median_values_bert[sample_name] = [median_val_bert]\n",
    "                median_values_jointbert[sample_name] = [median_val_jointbert]\n",
    "                median_values_deepmatcher[sample_name] = [median_val_deepmatcher]\n",
    "            \n",
    "            \n",
    "            # plot horizontal lines across the column, centered on the tick\n",
    "            ax.plot([tick-2*median_width, tick-1.0*median_width], [median_val_bert, median_val_bert],\n",
    "                   'k', lw=4, zorder=2)\n",
    "            ax.plot([tick-0.5*median_width, tick+0.5*median_width], [median_val_jointbert, median_val_jointbert],\n",
    "                   'k', lw=4, zorder=2)\n",
    "            ax.plot([tick+1.0*median_width, tick+2*median_width], [median_val_deepmatcher, median_val_deepmatcher],\n",
    "                   'k', lw=4, zorder=2)\n",
    "\n",
    "        if 'label' in median_values_bert.keys():\n",
    "                median_values_bert['label'].append(i)\n",
    "                median_values_jointbert['label'].append(i)\n",
    "                median_values_deepmatcher['label'].append(i)\n",
    "        else:\n",
    "            median_values_bert['label'] = [i]\n",
    "            median_values_jointbert['label'] = [i]\n",
    "            median_values_deepmatcher['label'] = [i]\n",
    "        \n",
    "        bert_df = explanations[(explanations['label']==i) & (explanations['model']=='BERT')]\n",
    "        jointbert_df = explanations[(explanations['label']==i) & (explanations['model']=='JointBERT')]\n",
    "        deepmatcher_df = explanations[(explanations['label']==i) & (explanations['model']=='Deepmatcher')]\n",
    "        \n",
    "        count_bert_correct = len(bert_df[bert_df['label'] == bert_df['label_bert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_bert_wrong = len(bert_df[bert_df['label'] != bert_df['label_bert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_bert_all = count_bert_correct + count_bert_wrong\n",
    "\n",
    "        count_jointbert_correct = len(jointbert_df[jointbert_df['label'] == jointbert_df['label_jointbert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_jointbert_wrong = len(jointbert_df[jointbert_df['label'] != jointbert_df['label_jointbert']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_jointbert_all = count_jointbert_correct + count_jointbert_wrong\n",
    "        \n",
    "        count_deepmatcher_correct = len(deepmatcher_df[deepmatcher_df['label'] == deepmatcher_df['label_deepmatcher']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_deepmatcher_wrong = len(deepmatcher_df[deepmatcher_df['label'] != deepmatcher_df['label_deepmatcher']].reset_index(level=\"wordclass\", drop=True).index.unique())\n",
    "        count_deepmatcher_all = count_deepmatcher_correct + count_deepmatcher_wrong\n",
    "        \n",
    "        print(f'Label: {i}: BERT correct: {count_bert_correct}/{count_bert_all}')\n",
    "        print(f'Label: {i}: JointBERT correct: {count_jointbert_correct}/{count_jointbert_all}')\n",
    "        print(f'Label: {i}: Deepmatcher correct: {count_deepmatcher_correct}/{count_deepmatcher_all}')\n",
    "    \n",
    "    median_bert_df = pd.DataFrame.from_dict(median_values_bert)\n",
    "    median_bert_df['model'] = 'BERT'\n",
    "    median_jointbert_df = pd.DataFrame.from_dict(median_values_jointbert)\n",
    "    median_jointbert_df['model'] = 'JointBERT'\n",
    "    median_deepmatcher_df = pd.DataFrame.from_dict(median_values_deepmatcher)\n",
    "    median_deepmatcher_df['model'] = 'Deepmatcher'\n",
    "    \n",
    "    median_to_file = median_bert_df.append(median_jointbert_df)\n",
    "    median_to_file = median_to_file.append(median_deepmatcher_df)\n",
    "    \n",
    "    #median_to_file.to_csv(f'../../data/processed/explain_labeling/pictures/MEDIAN_{filename}.csv', index=False, float_format=\"%.4f\")\n",
    "    \n",
    "    plt.subplots_adjust(bottom=0.25)\n",
    "    #g.fig.suptitle(f'Combined Classifications\\nChallenge: {name}')\n",
    "    plt.savefig(f'../../data/processed/explain_labeling/pictures/jointbert/onlybert/AVG_{filename}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_df = challenges_df[challenges_df['challenge_4'] == 0]\n",
    "training_examples_df = challenges_df[(challenges_df['challenge_7'] == 0) & (challenges_df['challenge_4'] == 0)]\n",
    "no_training_examples_df = challenges_df[(challenges_df['challenge_7'] == 1) & (challenges_df['challenge_4'] == 0)]\n",
    "\n",
    "\n",
    "dfs = {\n",
    "    #'train': training_examples_df,\n",
    "    'train+notrain': all_df\n",
    "    #'no_train': no_training_examples_df\n",
    "}\n",
    "\n",
    "for k, df in dfs.items():\n",
    "    print(f'Results for {k}:')\n",
    "    relevant_df = df\n",
    "    relevant_explanations_distilbert = explanations_distilbert.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_distilbert = relevant_explanations_distilbert[relevant_explanations_distilbert['label'] == relevant_explanations_distilbert['label_distilbert']]\n",
    "    relevant_explanations_wrong_distilbert = relevant_explanations_distilbert[relevant_explanations_distilbert['label'] != relevant_explanations_distilbert['label_distilbert']]\n",
    "\n",
    "\n",
    "    result_correct_distilbert = relevant_explanations_correct_distilbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_distilbert['wordclass'] = [j for i, j in result_correct_distilbert.index.tolist()]\n",
    "    result_correct_distilbert['model'] = 'DistilBERT'\n",
    "\n",
    "    result_wrong_distilbert = relevant_explanations_wrong_distilbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_distilbert['wordclass'] = [j for i, j in result_wrong_distilbert.index.tolist()]\n",
    "    result_wrong_distilbert['model'] = 'DistilBERT'\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    relevant_explanations_deepmatcher = explanations_deepmatcher.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_deepmatcher = relevant_explanations_deepmatcher[relevant_explanations_deepmatcher['label'] == relevant_explanations_deepmatcher['label_deepmatcher']]\n",
    "    relevant_explanations_wrong_deepmatcher = relevant_explanations_deepmatcher[relevant_explanations_deepmatcher['label'] != relevant_explanations_deepmatcher['label_deepmatcher']]\n",
    "\n",
    "\n",
    "    result_correct_deepmatcher = relevant_explanations_correct_deepmatcher.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_deepmatcher['wordclass'] = [j for i, j in result_correct_deepmatcher.index.tolist()]\n",
    "    result_correct_deepmatcher['model'] = 'Deepmatcher'\n",
    "\n",
    "    result_wrong_deepmatcher = relevant_explanations_wrong_deepmatcher.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_deepmatcher['wordclass'] = [j for i, j in result_wrong_deepmatcher.index.tolist()]\n",
    "    result_wrong_deepmatcher['model'] = 'Deepmatcher'\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    relevant_explanations_bert = explanations_bert.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_bert = relevant_explanations_bert[relevant_explanations_bert['label'] == relevant_explanations_bert['label_bert']]\n",
    "    relevant_explanations_wrong_bert = relevant_explanations_bert[relevant_explanations_bert['label'] != relevant_explanations_bert['label_bert']]\n",
    "\n",
    "\n",
    "    result_correct_bert = relevant_explanations_correct_bert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_bert['wordclass'] = [j for i, j in result_correct_bert.index.tolist()]\n",
    "    result_correct_bert['model'] = 'BERT'\n",
    "\n",
    "    result_wrong_bert = relevant_explanations_wrong_bert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_bert['wordclass'] = [j for i, j in result_wrong_bert.index.tolist()]\n",
    "    result_wrong_bert['model'] = 'BERT'\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    relevant_explanations_jointbert = explanations_jointbert.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_jointbert = relevant_explanations_jointbert[relevant_explanations_jointbert['label'] == relevant_explanations_jointbert['label_jointbert']]\n",
    "    relevant_explanations_wrong_jointbert = relevant_explanations_jointbert[relevant_explanations_jointbert['label'] != relevant_explanations_jointbert['label_jointbert']]\n",
    "\n",
    "\n",
    "    result_correct_jointbert = relevant_explanations_correct_jointbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_jointbert['wordclass'] = [j for i, j in result_correct_jointbert.index.tolist()]\n",
    "    result_correct_jointbert['model'] = 'JointBERT'\n",
    "\n",
    "    result_wrong_jointbert = relevant_explanations_wrong_jointbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_jointbert['wordclass'] = [j for i, j in result_wrong_jointbert.index.tolist()]\n",
    "    result_wrong_jointbert['model'] = 'JointBERT'\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    combined_results_correct =  result_correct_distilbert.append(result_correct_deepmatcher)\n",
    "    combined_results_correct =  combined_results_correct.append(result_correct_bert)\n",
    "    combined_results_correct =  combined_results_correct.append(result_correct_jointbert)\n",
    "\n",
    "    combined_results_wrong = result_wrong_distilbert.append(result_wrong_deepmatcher)\n",
    "    combined_results_wrong = combined_results_wrong.append(result_wrong_bert)\n",
    "    combined_results_wrong = combined_results_wrong.append(result_wrong_jointbert)\n",
    "\n",
    "    all_results = combined_results_correct.append(combined_results_wrong)\n",
    "\n",
    "    combined_results_correct = combined_results_correct[combined_results_correct['model'] != 'DistilBERT']\n",
    "    combined_results_wrong = combined_results_wrong[combined_results_wrong['model'] != 'DistilBERT']\n",
    "    all_results = all_results[all_results['model'] != 'DistilBERT']\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    jointbert_correct = all_results[(all_results['label'] == all_results['label_jointbert']) & (all_results['label'] != all_results['label_bert'])]\n",
    "    bert_correct = all_results[(all_results['label'] != all_results['label_jointbert']) & (all_results['label'] == all_results['label_bert'])]\n",
    "    deepmatcher_correct = all_results[(all_results['label'] != all_results['label_jointbert']) & (all_results['label'] != all_results['label_bert'])]\n",
    "    all_correct = all_results[(all_results['label'] == all_results['label_jointbert']) & (all_results['label'] == all_results['label_bert'])]\n",
    "    all_wrong = all_results[(all_results['label'] != all_results['label_jointbert']) & (all_results['label'] != all_results['label_bert'])]\n",
    "    \n",
    "    print('Combined performance:')\n",
    "    plot_explanations(all_results, f'3_combined_{k}')\n",
    "    print('Correct classifications:')\n",
    "    plot_explanations(combined_results_correct, f'3_correct_{k}')\n",
    "    print('Wrong classifications:')\n",
    "    plot_explanations(combined_results_wrong, f'3_wrong_{k}')\n",
    "\n",
    "    print('##############################')\n",
    "    \n",
    "    print('Only JointBERT correct:')\n",
    "    plot_explanations(jointbert_correct, f'3_only_joint_correct_{k}')\n",
    "\n",
    "    print('Only BERT correct:')\n",
    "    plot_explanations(bert_correct, f'3_only_bert_correct_{k}')\n",
    "    \n",
    "    print('Only Deepmatcher correct:')\n",
    "    plot_explanations(deepmatcher_correct, f'3_only_deepmatcher_correct_{k}')\n",
    "    \n",
    "    print('All correct:')\n",
    "    plot_explanations(all_correct, f'3_all_correct_{k}')\n",
    "\n",
    "    print('All wrong:')\n",
    "    plot_explanations(all_wrong, f'3_all_wrong_{k}')\n",
    "    \n",
    "    print('Combined performance:')\n",
    "    plot_explanations_avg(all_results, f'3_combined_{k}')\n",
    "    print('Correct classifications:')\n",
    "    plot_explanations_avg(combined_results_correct, f'3_correct_{k}')\n",
    "    print('Wrong classifications:')\n",
    "    plot_explanations_avg(combined_results_wrong, f'3_wrong_{k}')\n",
    "\n",
    "    print('##############################')\n",
    "\n",
    "    print('Only JointBERT correct:')\n",
    "    plot_explanations_avg(jointbert_correct, f'3_only_joint_correct_{k}')\n",
    "\n",
    "    print('Only BERT correct:')\n",
    "    plot_explanations_avg(bert_correct, f'3_only_bert_correct_{k}')\n",
    "\n",
    "    print('Only Deepmatcher correct:')\n",
    "    plot_explanations_avg(deepmatcher_correct, f'3_only_deepmatcher_correct_{k}')\n",
    "\n",
    "    print('All correct:')\n",
    "    plot_explanations_avg(all_correct, f'3_all_correct_{k}')\n",
    "\n",
    "    print('All wrong:')\n",
    "    plot_explanations_avg(all_wrong, f'3_all_wrong_{k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "challenges = {'challenge_1':'Solvable by looking at model numbers',\n",
    "              'challenge_2':'No model number for one of the two but solvable by looking at attribute words'\n",
    "              'challenge_5':'both have many training examples',\n",
    "              'challenge_6':'both have few training examples',\n",
    "              'challenge_7':'no training examples'}\n",
    "\n",
    "\n",
    "\n",
    "for challenge, name in challenges.items():\n",
    "    \n",
    "    print(f'Results for {name}:')\n",
    "    relevant_df = challenges_df[challenges_df[challenge] == 1]\n",
    "    relevant_explanations_distilbert = explanations_distilbert.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_distilbert = relevant_explanations_distilbert[relevant_explanations_distilbert['label'] == relevant_explanations_distilbert['label_distilbert']]\n",
    "    relevant_explanations_wrong_distilbert = relevant_explanations_distilbert[relevant_explanations_distilbert['label'] != relevant_explanations_distilbert['label_distilbert']]\n",
    "\n",
    "\n",
    "    result_correct_distilbert = relevant_explanations_correct_distilbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_distilbert['wordclass'] = [j for i, j in result_correct_distilbert.index.tolist()]\n",
    "    result_correct_distilbert['model'] = 'DistilBERT'\n",
    "\n",
    "    result_wrong_distilbert = relevant_explanations_wrong_distilbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_distilbert['wordclass'] = [j for i, j in result_wrong_distilbert.index.tolist()]\n",
    "    result_wrong_distilbert['model'] = 'DistilBERT'\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    relevant_explanations_deepmatcher = explanations_deepmatcher.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_deepmatcher = relevant_explanations_deepmatcher[relevant_explanations_deepmatcher['label'] == relevant_explanations_deepmatcher['label_deepmatcher']]\n",
    "    relevant_explanations_wrong_deepmatcher = relevant_explanations_deepmatcher[relevant_explanations_deepmatcher['label'] != relevant_explanations_deepmatcher['label_deepmatcher']]\n",
    "\n",
    "\n",
    "    result_correct_deepmatcher = relevant_explanations_correct_deepmatcher.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_deepmatcher['wordclass'] = [j for i, j in result_correct_deepmatcher.index.tolist()]\n",
    "    result_correct_deepmatcher['model'] = 'Deepmatcher'\n",
    "\n",
    "    result_wrong_deepmatcher = relevant_explanations_wrong_deepmatcher.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_deepmatcher['wordclass'] = [j for i, j in result_wrong_deepmatcher.index.tolist()]\n",
    "    result_wrong_deepmatcher['model'] = 'Deepmatcher'\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    relevant_explanations_bert = explanations_bert.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_bert = relevant_explanations_bert[relevant_explanations_bert['label'] == relevant_explanations_bert['label_bert']]\n",
    "    relevant_explanations_wrong_bert = relevant_explanations_bert[relevant_explanations_bert['label'] != relevant_explanations_bert['label_bert']]\n",
    "\n",
    "\n",
    "    result_correct_bert = relevant_explanations_correct_bert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_bert['wordclass'] = [j for i, j in result_correct_bert.index.tolist()]\n",
    "    result_correct_bert['model'] = 'BERT'\n",
    "\n",
    "    result_wrong_bert = relevant_explanations_wrong_bert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_bert['wordclass'] = [j for i, j in result_wrong_bert.index.tolist()]\n",
    "    result_wrong_bert['model'] = 'BERT'\n",
    "\n",
    "    ##########################################\n",
    "\n",
    "    relevant_explanations_jointbert = explanations_jointbert.loc[relevant_df.index]\n",
    "\n",
    "    relevant_explanations_correct_jointbert = relevant_explanations_jointbert[relevant_explanations_jointbert['label'] == relevant_explanations_jointbert['label_jointbert']]\n",
    "    relevant_explanations_wrong_jointbert = relevant_explanations_jointbert[relevant_explanations_jointbert['label'] != relevant_explanations_jointbert['label_jointbert']]\n",
    "\n",
    "\n",
    "    result_correct_jointbert = relevant_explanations_correct_jointbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_correct_jointbert['wordclass'] = [j for i, j in result_correct_jointbert.index.tolist()]\n",
    "    result_correct_jointbert['model'] = 'JointBERT'\n",
    "\n",
    "    result_wrong_jointbert = relevant_explanations_wrong_jointbert.groupby(['pair_id','wordclass']).mean()\n",
    "    result_wrong_jointbert['wordclass'] = [j for i, j in result_wrong_jointbert.index.tolist()]\n",
    "    result_wrong_jointbert['model'] = 'JointBERT'\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    combined_results_correct =  result_correct_distilbert.append(result_correct_deepmatcher)\n",
    "    combined_results_correct =  combined_results_correct.append(result_correct_bert)\n",
    "    combined_results_correct =  combined_results_correct.append(result_correct_jointbert)\n",
    "\n",
    "    combined_results_wrong = result_wrong_distilbert.append(result_wrong_deepmatcher)\n",
    "    combined_results_wrong = combined_results_wrong.append(result_wrong_bert)\n",
    "    combined_results_wrong = combined_results_wrong.append(result_wrong_jointbert)\n",
    "\n",
    "    all_results = combined_results_correct.append(combined_results_wrong)\n",
    "\n",
    "    combined_results_correct = combined_results_correct[combined_results_correct['model'] != 'DistilBERT']\n",
    "    combined_results_wrong = combined_results_wrong[combined_results_wrong['model'] != 'DistilBERT']\n",
    "    all_results = all_results[all_results['model'] != 'DistilBERT']\n",
    "\n",
    "    ###########################################\n",
    "\n",
    "    jointbert_correct = all_results[(all_results['label'] == all_results['label_jointbert']) & (all_results['label'] != all_results['label_bert'])]\n",
    "    bert_correct = all_results[(all_results['label'] != all_results['label_jointbert']) & (all_results['label'] == all_results['label_bert'])]\n",
    "    deepmatcher_correct = all_results[(all_results['label'] != all_results['label_jointbert']) & (all_results['label'] != all_results['label_bert'])]\n",
    "    all_correct = all_results[(all_results['label'] == all_results['label_jointbert']) & (all_results['label'] == all_results['label_bert'])]\n",
    "    all_wrong = all_results[(all_results['label'] != all_results['label_jointbert']) & (all_results['label'] != all_results['label_bert'])]\n",
    "    \n",
    "    \n",
    "    print('Combined performance:')\n",
    "    plot_explanations(all_results, f'3_combined_{name}')\n",
    "    \n",
    "    print('All correct:')\n",
    "    plot_explanations(all_correct, f'3_all_correct_{name}')\n",
    "    \n",
    "    print('All wrong:')\n",
    "    plot_explanations(all_wrong, f'3_all_wrong_{name}')\n",
    "    \n",
    "    print('Only JointBERT correct:')\n",
    "    plot_explanations(jointbert_correct, f'3_only_joint_correct_{name}')\n",
    "\n",
    "    print('Only BERT correct:')\n",
    "    plot_explanations(bert_correct, f'3_only_bert_correct_{name}')\n",
    "    \n",
    "    print('Only Deepmatcher correct:')\n",
    "    plot_explanations(deepmatcher_correct, f'3_only_deepmatcher_correct_{name}')\n",
    "    \n",
    "    print('Combined performance:')\n",
    "    plot_explanations_avg(all_results, f'3_combined_{name}')\n",
    "\n",
    "    print('All correct:')\n",
    "    plot_explanations_avg(all_correct, f'3_all_correct_{name}')\n",
    "\n",
    "    print('All wrong:')\n",
    "    plot_explanations_avg(all_wrong, f'3_all_wrong_{name}')\n",
    "    \n",
    "    print('Only JointBERT correct:')\n",
    "    plot_explanations_avg(jointbert_correct, f'3_only_joint_correct_{name}')\n",
    "\n",
    "    print('Only BERT correct:')\n",
    "    plot_explanations_avg(bert_correct, f'3_only_bert_correct_{name}')\n",
    "    \n",
    "    print('Only Deepmatcher correct:')\n",
    "    plot_explanations_avg(deepmatcher_correct, f'3_only_deepmatcher_correct_{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jointbert)",
   "language": "python",
   "name": "conda_jointbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
