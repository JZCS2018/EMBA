{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5308df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ac41f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dire = '/home/ubuntu/dataset_em/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a01479c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\r\n",
      "/bin/bash: error importing function definition for `switchml'\r\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\r\n",
      "/bin/bash: error importing function definition for `_moduleraw'\r\n",
      "tableA.csv  tableB.csv\ttest.csv  train.csv  valid.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/ubuntu/dataset_em/amazon_google/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6951ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = pd.read_csv(dire + 'amazon_google/tableA.csv').fillna('')\n",
    "ta['cluster_id_left'] = ta['manufacturer'].tolist()\n",
    "tb = pd.read_csv(dire + 'amazon_google/tableB.csv').fillna('')\n",
    "tb['cluster_id_right'] = tb['manufacturer'].tolist()\n",
    "\n",
    "ttr = pd.read_csv(dire + 'amazon_google/train.csv')\n",
    "ttr.rename(columns={\"ltable_id\": \"id_left\", \"rtable_id\": \"id_right\"},inplace = True)\n",
    "tval = pd.read_csv(dire + 'amazon_google/valid.csv')\n",
    "tval.rename(columns={\"ltable_id\": \"id_left\", \"rtable_id\": \"id_right\"},inplace = True)\n",
    "tte = pd.read_csv(dire + 'amazon_google/test.csv')\n",
    "tte.rename(columns={\"ltable_id\": \"id_left\", \"rtable_id\": \"id_right\"},inplace = True)\n",
    "ta.rename(columns={\"id\": \"id_left\", \"title\": \"title_left\",\"manufacturer\":\"manufacturer_left\", \"price\":\"price_left\"},\n",
    "         inplace = True)\n",
    "tb.rename(columns={\"id\": \"id_right\", \"title\": \"title_right\",\"manufacturer\":\"manufacturer_right\", \"price\":\"price_right\"},\n",
    "         inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49131cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>title_left</th>\n",
       "      <th>manufacturer_left</th>\n",
       "      <th>price_left</th>\n",
       "      <th>cluster_id_left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>clickart 950 000 premier image pack ( dvd-rom )</td>\n",
       "      <td>broderbund</td>\n",
       "      <td></td>\n",
       "      <td>broderbund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ca international arcserve lap/desktop oem 30pk</td>\n",
       "      <td>computer associates</td>\n",
       "      <td></td>\n",
       "      <td>computer associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>noah 's ark activity center ( jewel case ages ...</td>\n",
       "      <td>victory multimedia</td>\n",
       "      <td></td>\n",
       "      <td>victory multimedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>peachtree by sage premium accounting for nonpr...</td>\n",
       "      <td>sage software</td>\n",
       "      <td>599.99</td>\n",
       "      <td>sage software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>singing coach unlimited</td>\n",
       "      <td>carry-a-tune technologies</td>\n",
       "      <td>99.99</td>\n",
       "      <td>carry-a-tune technologies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_left                                         title_left  \\\n",
       "0        0    clickart 950 000 premier image pack ( dvd-rom )   \n",
       "1        1     ca international arcserve lap/desktop oem 30pk   \n",
       "2        2  noah 's ark activity center ( jewel case ages ...   \n",
       "3        3  peachtree by sage premium accounting for nonpr...   \n",
       "4        4                            singing coach unlimited   \n",
       "\n",
       "           manufacturer_left price_left            cluster_id_left  \n",
       "0                 broderbund                            broderbund  \n",
       "1        computer associates                   computer associates  \n",
       "2         victory multimedia                    victory multimedia  \n",
       "3              sage software     599.99              sage software  \n",
       "4  carry-a-tune technologies      99.99  carry-a-tune technologies  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6ecb3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "cluster_id_set_left = set()\n",
    "cluster_id_set_left.update(ta['cluster_id_left'].tolist())\n",
    "cluster_id_set_right = set()\n",
    "cluster_id_set_right.update(tb['cluster_id_right'].tolist())\n",
    "cluster_id_set_left.update(cluster_id_set_right)\n",
    "enc.fit(list(cluster_id_set_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9096e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(df_l, df_r, gs):\n",
    "    res = gs.merge(df_l, on = 'id_left')\n",
    "    res = res.merge(df_r, on = 'id_right') \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e245e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merge_data(ta, tb, ttr)\n",
    "train['pair_id'] = train['id_left'].astype('str') + ' & ' + train['id_right'].astype('str')\n",
    "val = merge_data(ta, tb, tval)\n",
    "val['pair_id'] = val['id_left'].astype('str') + ' & ' + val['id_right'].astype('str')\n",
    "test = merge_data(ta, tb, tte)\n",
    "test['pair_id'] = test['id_left'].astype('str') + ' & ' + test['id_right'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03714b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c0e859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffa28b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_to_bert(dataset, tokenizer, comb_func, cutting_func=None, multi_encoder=None):\n",
    "    dataset = dataset.fillna('')\n",
    "\n",
    "    if multi_encoder is None:\n",
    "        try:\n",
    "            cluster_id_set_left = set()\n",
    "            cluster_id_set_left.update(dataset['cluster_id_left'].tolist())\n",
    "            cluster_id_set_right = set()\n",
    "            cluster_id_set_right.update(dataset['cluster_id_right'].tolist())\n",
    "            cluster_id_set_left.update(cluster_id_set_right)\n",
    "            dataset = dataset.rename(columns={'cluster_id_left': 'label_multi1', 'cluster_id_right': 'label_multi2'})\n",
    "            label_enc = LabelEncoder()\n",
    "            label_enc.fit(list(cluster_id_set_left))\n",
    "            dataset['label_multi1'] = label_enc.transform(dataset['label_multi1'])\n",
    "            dataset['label_multi2'] = label_enc.transform(dataset['label_multi2'])\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "    else:\n",
    "        dataset = dataset.rename(columns={'cluster_id_left': 'label_multi1', 'cluster_id_right': 'label_multi2'})\n",
    "        try:\n",
    "            dataset['label_multi1'] = multi_encoder.transform(dataset['label_multi1'])\n",
    "            dataset['label_multi2'] = multi_encoder.transform(dataset['label_multi2'])\n",
    "        except ValueError:\n",
    "            dataset['label_multi1'] = 0\n",
    "            dataset['label_multi2'] = 0\n",
    "\n",
    "    print(f'Before cutting:')\n",
    "#     _print_attribute_stats(dataset, attributes)\n",
    "#     if cutting_func:\n",
    "#         tqdm.pandas(desc='Cutting attributes')\n",
    "#         dataset = dataset.progress_apply(cutting_func, axis=1)\n",
    "#         print(f'After cutting:')\n",
    "#         _print_attribute_stats(dataset, attributes)\n",
    "\n",
    "    dataset['sequence_left'], dataset['sequence_left_titleonly'], dataset['sequence_right'], dataset[\n",
    "        'sequence_right_titleonly'] = comb_func(dataset)\n",
    "\n",
    "    dataset['sequence_left'] = dataset['sequence_left'].str.split()\n",
    "    dataset['sequence_left'] = dataset['sequence_left'].str.join(' ')\n",
    "    dataset['sequence_right'] = dataset['sequence_right'].str.split()\n",
    "    dataset['sequence_right'] = dataset['sequence_right'].str.join(' ')\n",
    "\n",
    "    dataset['sequence_left_titleonly'] = dataset['sequence_left_titleonly'].str.split()\n",
    "    dataset['sequence_left_titleonly'] = dataset['sequence_left_titleonly'].str.join(' ')\n",
    "    dataset['sequence_right_titleonly'] = dataset['sequence_right_titleonly'].str.split()\n",
    "    dataset['sequence_right_titleonly'] = dataset['sequence_right_titleonly'].str.join(' ')\n",
    "\n",
    "    tqdm.pandas(desc='Tokenizing left sequence for inspection')\n",
    "    dataset['sequence_left_inspect'] = dataset['sequence_left'].progress_apply(lambda x: tokenizer.tokenize(x))\n",
    "    dataset['sequence_left_titleonly_inspect'] = dataset['sequence_left_titleonly'].progress_apply(\n",
    "        lambda x: tokenizer.tokenize(x))\n",
    "    tqdm.pandas(desc='Tokenizing right sequence for inspection')\n",
    "    dataset['sequence_right_inspect'] = dataset['sequence_right'].progress_apply(lambda x: tokenizer.tokenize(x))\n",
    "    dataset['sequence_right_titleonly_inspect'] = dataset['sequence_right_titleonly'].progress_apply(\n",
    "        lambda x: tokenizer.tokenize(x))\n",
    "\n",
    "    dataset_combined_length = dataset.apply(\n",
    "        lambda x: len(x['sequence_left_inspect']) + len(x['sequence_right_inspect']), axis=1)\n",
    "    dataset_combined_length_binned = pd.cut(dataset_combined_length, [-1, 32, 64, 128, 256, 512, 50000],\n",
    "                                            labels=['32', '64', '128', '256', '512', '50000'])\n",
    "    print('Full sequence:')\n",
    "#     plt.hist(dataset_combined_length_binned)\n",
    "#     plt.show()\n",
    "\n",
    "    dataset_combined_length = dataset.apply(\n",
    "        lambda x: len(x['sequence_left_titleonly_inspect']) + len(x['sequence_right_titleonly_inspect']), axis=1)\n",
    "    dataset_combined_length_binned = pd.cut(dataset_combined_length, [-1, 32, 64, 128, 256, 512, 50000],\n",
    "                                            labels=['32', '64', '128', '256', '512', '50000'])\n",
    "    print('Title only sequence:')\n",
    "#     plt.hist(dataset_combined_length_binned)\n",
    "#     plt.show()\n",
    "\n",
    "    try:\n",
    "        dataset_reduced = dataset[\n",
    "            ['label', 'label_multi1', 'label_multi2', 'pair_id', 'sequence_left', 'sequence_right']]\n",
    "        dataset_reduced_titleonly = dataset[\n",
    "            ['label', 'label_multi1', 'label_multi2', 'pair_id', 'sequence_left_titleonly',\n",
    "             'sequence_right_titleonly']].copy()\n",
    "    except KeyError:\n",
    "        dataset_reduced = dataset[['label', 'pair_id', 'sequence_left', 'sequence_right']]\n",
    "        dataset_reduced_titleonly = dataset[\n",
    "            ['label', 'pair_id', 'sequence_left_titleonly', 'sequence_right_titleonly']].copy()\n",
    "\n",
    "    dataset_reduced_titleonly = dataset_reduced_titleonly.rename(columns={'sequence_left_titleonly': 'sequence_left',\n",
    "                                                                          'sequence_right_titleonly': 'sequence_right'})\n",
    "\n",
    "    dataset_inspect = dataset[\n",
    "        ['sequence_left', 'sequence_left_inspect', 'sequence_left_titleonly', 'sequence_left_titleonly_inspect',\n",
    "         'sequence_right', 'sequence_right_inspect', 'sequence_right_titleonly', 'sequence_right_titleonly_inspect',\n",
    "         'pair_id']]\n",
    "\n",
    "    return dataset_reduced, dataset_reduced_titleonly, dataset_inspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87a68f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _att_to_seq_amazongoogle(dataset):\n",
    "    seq_left = dataset['manufacturer_left'] + ' ' + dataset['title_left'] + ' ' + ' ' + \\\n",
    "               dataset['price_left'].astype(str)\n",
    "    seq_left_titleonly = dataset['manufacturer_left'] + ' ' + dataset['title_left']\n",
    "    seq_right = dataset['manufacturer_right'] + ' ' + dataset['title_right'] + ' ' + \\\n",
    "                dataset['price_right'].astype(str)\n",
    "    seq_right_titleonly = dataset['manufacturer_right'] + ' ' + dataset['title_right']\n",
    "    return seq_left, seq_left_titleonly, seq_right, seq_right_titleonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee8d852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jointbert/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Tokenizing left sequence for inspection:   6%|▌         | 419/6874 [00:00<00:01, 4184.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cutting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing left sequence for inspection: 100%|██████████| 6874/6874 [00:01<00:00, 4524.24it/s]\n",
      "Tokenizing left sequence for inspection: 100%|██████████| 6874/6874 [00:01<00:00, 5008.60it/s]\n",
      "Tokenizing right sequence for inspection: 100%|██████████| 6874/6874 [00:01<00:00, 4590.10it/s]\n",
      "Tokenizing right sequence for inspection: 100%|██████████| 6874/6874 [00:01<00:00, 5130.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full sequence:\n",
      "Title only sequence:\n"
     ]
    }
   ],
   "source": [
    "df_gs, df_gs_titleonly, df_inspect = process_to_bert(train, tokenizer,\n",
    "                                                                 _att_to_seq_amazongoogle, multi_encoder=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7469f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs.to_pickle(f'amazongoogle-train-bert.pkl.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5588c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/jointbert/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "Tokenizing left sequence for inspection:  20%|█▉        | 452/2293 [00:00<00:00, 4510.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cutting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing left sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 4474.50it/s]\n",
      "Tokenizing left sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 4980.94it/s]\n",
      "Tokenizing right sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 4515.57it/s]\n",
      "Tokenizing right sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 5071.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full sequence:\n",
      "Title only sequence:\n"
     ]
    }
   ],
   "source": [
    "df_gs, df_gs_titleonly, df_inspect = process_to_bert(val, tokenizer,\n",
    "                                                                 _att_to_seq_amazongoogle, multi_encoder=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c267cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs.to_csv(f'amazongoogle-valid.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "551948b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing left sequence for inspection:  21%|██        | 481/2293 [00:00<00:00, 4802.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cutting:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing left sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 4543.03it/s]\n",
      "Tokenizing left sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 5048.17it/s]\n",
      "Tokenizing right sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 4591.44it/s]\n",
      "Tokenizing right sequence for inspection: 100%|██████████| 2293/2293 [00:00<00:00, 4283.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full sequence:\n",
      "Title only sequence:\n"
     ]
    }
   ],
   "source": [
    "df_gs, df_gs_titleonly, df_inspect = process_to_bert(test, tokenizer,\n",
    "                                                                 _att_to_seq_amazongoogle, multi_encoder=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dabd16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs.to_pickle(f'amazongoogle-gs-bert.pkl.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28907da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f25a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_jointbert)",
   "language": "python",
   "name": "conda_jointbert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
